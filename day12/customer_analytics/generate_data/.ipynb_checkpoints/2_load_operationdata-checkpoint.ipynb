{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751bf541-3371-4469-b3a1-a76449c055f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1d0e0f-4fda-412e-a6e8-1711b93fb1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faker\n",
      "  Downloading faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, faker\n",
      "Successfully installed faker-37.0.0 tzdata-2025.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9258e1-b5d2-4526-8b8a-4b214bf4e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/spark/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/aws-glue-libs/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/aws-glue-libs/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/glue_user/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/glue_user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/glue_user/.ivy2/jars\n",
      "mysql#mysql-connector-java added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1e0662d5-5dba-4a1c-ae58-cefd0be03cbe;1.0\n",
      "\tconfs: [default]\n",
      "mysql#mysql-connector-java;8.0.33 is relocated to com.mysql#mysql-connector-j;8.0.33. Please update your dependencies.\n",
      "\tfound mysql#mysql-connector-java;8.0.33 in central\n",
      "\tfound com.mysql#mysql-connector-j;8.0.33 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.9 in central\n",
      "downloading https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar ...\n",
      "\t[SUCCESSFUL ] com.mysql#mysql-connector-j;8.0.33!mysql-connector-j.jar (1620ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.21.9/protobuf-java-3.21.9.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.21.9!protobuf-java.jar(bundle) (520ms)\n",
      ":: resolution report :: resolve 6007ms :: artifacts dl 2145ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;3.21.9 from central in [default]\n",
      "\tcom.mysql#mysql-connector-j;8.0.33 from central in [default]\n",
      "\tmysql#mysql-connector-java;8.0.33 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   3   |   3   |   0   ||   2   |   2   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1e0662d5-5dba-4a1c-ae58-cefd0be03cbe\n",
      "\tconfs: [default]\n",
      "\t2 artifacts copied, 0 already retrieved (4055kB/15ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Spark Session with MySQL JDBC Driver\n",
    "spark = SparkSession.builder.appName(\"load_operation_data\") \\\n",
    "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.33\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403fbdd2-43bb-41cb-bfe3-7d836723017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker for realistic data\n",
    "fake = Faker()\n",
    "\n",
    "# Generate Customers\n",
    "def generate_customers(n):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, fake.first_name(), fake.last_name(), fake.email(), fake.phone_number(),\n",
    "          fake.address(), fake.city(), fake.state(), fake.zipcode(), fake.country()) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"customer_id\", \"first_name\", \"last_name\", \"email\", \"phone\", \"address\", \"city\", \"state\", \"zip_code\", \"country\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c893ab-171b-49e9-8825-fb2abfec9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+--------------------+--------------------+--------------------+-----------------+--------------+--------+--------------------+\n",
      "|customer_id| first_name|last_name|               email|               phone|             address|             city|         state|zip_code|             country|\n",
      "+-----------+-----------+---------+--------------------+--------------------+--------------------+-----------------+--------------+--------+--------------------+\n",
      "|          1|     Alyssa| Anderson|   rking@example.net|   498-863-7106x3591|1729 King Inlet S...|East Williamville|     Minnesota|   56790|               Japan|\n",
      "|          2|  Christine|  Jackson|smithcheryl@examp...|        392.695.3629|07003 William Spu...|      West Andrew|     Tennessee|   55395|              Jordan|\n",
      "|          3|      Chloe|    Ramos|william25@example...|+1-887-594-7524x8...|474 David Light\\n...| East Howardmouth|North Carolina|   09707|               Nepal|\n",
      "|          4|   Brittany| Guerrero|albert51@example.com|    871-843-7144x251|01709 Shane Inlet...|    South Jessica|      Oklahoma|   00941|              Turkey|\n",
      "|          5|     Joseph|   Nelson|jennifer35@exampl...|   (740)275-1069x085|6074 Wilson Route...|         Susanton|        Oregon|   84225|     Kyrgyz Republic|\n",
      "|          6|      James|    Brown|sanchezangela@exa...|     +1-554-740-5076|60705 Jackson Isl...| West Jessicafort|     Louisiana|   16730|                Cuba|\n",
      "|          7|      James|  Mathews|  lisa25@example.org|   (791)632-9863x950|94511 Johnson Bri...|      Arroyoburgh|         Maine|   49535|              Cyprus|\n",
      "|          8|Christopher| Mccarthy|henrycannon@examp...|       (304)980-2495|7657 Cordova Mall...|        South Joy|South Carolina|   72293|                Iraq|\n",
      "|          9|     Daniel|   Bryant|amandapace@exampl...| (526)407-9870x87604|USCGC Fields\\nFPO...|    Lake Jonathan|     Louisiana|   08981|          Uzbekistan|\n",
      "|         10|    Jasmine|   Parker|nicole81@example.org|    001-512-783-3604|3684 Vargas Overp...|          Wuburgh|          Iowa|   80826|                Niue|\n",
      "|         11|     Karina|   Fowler|ortizkathy@exampl...|   (740)916-8420x254|PSC 6646, Box 298...|        Patelbury|      Kentucky|   74884|Netherlands Antilles|\n",
      "|         12|      Oscar|  Schmidt|   tcook@example.org|  355-289-3357x68210|15004 Wesley Lodg...|  Lake Frankhaven|  Pennsylvania|   68230|                Peru|\n",
      "|         13|     Ashley|  Hensley| tcarson@example.net|001-671-321-3449x...|PSC 7116, Box 844...|   Christopherton|       Arizona|   57161|             Ukraine|\n",
      "|         14|     Steven| Martinez|samantha47@exampl...|       (962)443-9421|75934 Walker Caus...|      Matthewbury|       Montana|   79189|               Italy|\n",
      "|         15|    Matthew|  Aguilar|patriciawalsh@exa...|        915.700.3400|13304 Long Estate...|       North John|    New Mexico|   94904|               Congo|\n",
      "|         16|Christopher|   Cooper| kfarmer@example.com|        556-348-1212|675 Rose Crossroa...| Port Robertburgh|        Alaska|   26665|           Greenland|\n",
      "|         17|      Jason|   Steele|jeremiah55@exampl...|+1-857-201-6946x1471|PSC 9459, Box 283...|    Figueroamouth|      Colorado|   64277|         New Zealand|\n",
      "|         18|    Kenneth|  Estrada|garycastaneda@exa...|  222-992-3530x64758|7522 Weber Prairi...|       Davidshire|        Nevada|   47231|         Saint Lucia|\n",
      "|         19|        Amy|    Perez|rfischer@example.net|        818-338-9974|438 Smith Parkway...|   Lake Elizabeth|      Delaware|   40444|              Latvia|\n",
      "|         20|    Sabrina|   Harper|jessica99@example...|          7329953685|643 Smith Lane Su...|    Bartlettshire|South Carolina|   77480|                Chad|\n",
      "+-----------+-----------+---------+--------------------+--------------------+--------------------+-----------------+--------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate Data\n",
    "customers_df = generate_customers(10000)\n",
    "customers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a684edff-d8d8-4e71-a3b2-611510cb17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully written to MySQL!\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate emails before writing to MySQL\n",
    "customers_df = customers_df.dropDuplicates([\"email\"])\n",
    "\n",
    "customers_df.write.jdbc(url=USER_MYSQL_URL, table=\"Customers\", mode=\"append\", properties=MYSQL_PROPERTIES)\n",
    "\n",
    "print(\"✅ Data successfully written to MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315fae67-1777-4f90-91bd-00e7c87f9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate Products\n",
    "def generate_products(n):\n",
    "    categories = [\"Electronics\", \"Clothing\", \"Home & Kitchen\", \"Books\", \"Toys\", \"Sports\"]\n",
    "    return spark.createDataFrame(\n",
    "        [(i, fake.word().capitalize(), fake.sentence(nb_words=6), \n",
    "          random.choice(categories), round(random.uniform(5, 500), 2), random.randint(10, 1000)) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"product_id\", \"name\", \"description\", \"category\", \"price\", \"stock_quantity\"]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate Payments\n",
    "def generate_payments(n, max_order_id):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.randint(1, max_order_id), fake.date_this_decade(), \n",
    "          random.choice([\"Credit Card\", \"PayPal\", \"Gift Card\", \"Bank Transfer\"]), \n",
    "          round(random.uniform(10, 500), 2), random.choice([\"Success\", \"Failed\", \"Pending\"])) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"payment_id\", \"order_id\", \"payment_date\", \"payment_method\", \"amount\", \"status\"]\n",
    "    )\n",
    "\n",
    "# Generate Purchase History\n",
    "def generate_purchase_history(n, max_customer_id, max_order_id):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.randint(1, max_customer_id), random.randint(1, max_order_id), \n",
    "          fake.date_this_decade(), round(random.uniform(10, 500), 2)) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"history_id\", \"customer_id\", \"order_id\", \"purchase_date\", \"amount_spent\"]\n",
    "    )\n",
    "\n",
    "# Generate Usage History\n",
    "def generate_usage_history(n, max_customer_id, max_product_id):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.randint(1, max_customer_id), random.randint(1, max_product_id), \n",
    "          fake.date_this_decade(), fake.sentence(nb_words=10), \n",
    "          random.choice([\"Returned\", \"Not Returned\"])) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"usage_id\", \"customer_id\", \"product_id\", \"usage_date\", \"feedback\", \"return_status\"]\n",
    "    )\n",
    "\n",
    "# Generate Transactions\n",
    "def generate_transactions(n, max_customer_id, max_order_id, max_payment_id):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.randint(1, max_customer_id), random.randint(1, max_order_id), \n",
    "          random.randint(1, max_payment_id), fake.date_this_decade(), \n",
    "          round(random.uniform(10, 500), 2), random.choice([\"Purchase\", \"Refund\"]), \n",
    "          random.choice([\"Completed\", \"Failed\", \"Pending\"])) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"transaction_id\", \"customer_id\", \"order_id\", \"payment_id\", \"transaction_date\", \n",
    "         \"amount\", \"transaction_type\", \"status\"]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678465d-efb9-4285-9fc4-1df92b496282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1e42e6-fc97-4c45-b6be-d697c505126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "products_df = generate_products(1000)\n",
    "\n",
    "products_df.write.jdbc(url=PRODUCT_MYSQL_URL, table=\"Products\", mode=\"append\", properties=MYSQL_PROPERTIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf86dde5-8a0b-4b1b-bc7e-a0487b7f70b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_orders\u001b[39m(n):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[1;32m      8\u001b[0m         [(i, random\u001b[38;5;241m.\u001b[39mchoice(valid_customer_ids), fake\u001b[38;5;241m.\u001b[39mdate_this_decade(), \n\u001b[1;32m      9\u001b[0m           random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPending\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShipped\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelivered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 15\u001b[0m orders_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_orders\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m orders_df\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mgenerate_orders\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_orders\u001b[39m(n):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[0;32m----> 8\u001b[0m         [(i, random\u001b[38;5;241m.\u001b[39mchoice(valid_customer_ids), fake\u001b[38;5;241m.\u001b[39mdate_this_decade(), \n\u001b[1;32m      9\u001b[0m           random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPending\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShipped\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelivered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \n\u001b[1;32m     10\u001b[0m           \u001b[38;5;28mround\u001b[39m(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m500\u001b[39m), \u001b[38;5;241m2\u001b[39m)) \n\u001b[1;32m     11\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)], \n\u001b[1;32m     12\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_orders\u001b[39m(n):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\n\u001b[0;32m----> 8\u001b[0m         [(i, \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_customer_ids\u001b[49m\u001b[43m)\u001b[49m, fake\u001b[38;5;241m.\u001b[39mdate_this_decade(), \n\u001b[1;32m      9\u001b[0m           random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPending\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShipped\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelivered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \n\u001b[1;32m     10\u001b[0m           \u001b[38;5;28mround\u001b[39m(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m500\u001b[39m), \u001b[38;5;241m2\u001b[39m)) \n\u001b[1;32m     11\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)], \n\u001b[1;32m     12\u001b[0m         [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/random.py:378\u001b[0m, in \u001b[0;36mRandom.choice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# raises IndexError if seq is empty\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "customers_df = spark.read.jdbc(url=USER_MYSQL_URL, table=\"Customers\", properties=MYSQL_PROPERTIES)\n",
    "\n",
    "valid_customer_ids = [row[\"customer_id\"] for row in customers_df.select(\"customer_id\").collect()]\n",
    "\n",
    "# ✅ Generate Orders using only valid customer IDs\n",
    "def generate_orders(n):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.choice(valid_customer_ids), fake.date_this_decade(), \n",
    "          random.choice([\"Pending\", \"Shipped\", \"Delivered\", \"Cancelled\"]), \n",
    "          round(random.uniform(10, 500), 2)) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"order_id\", \"customer_id\", \"order_date\", \"status\", \"total_amount\"]\n",
    "    )\n",
    "\n",
    "orders_df = generate_orders(100000)\n",
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddd3d9-b125-46b3-91f7-084c438f86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orders_df.write.jdbc(url=ORDER_MYSQL_URL, table=\"Orders\", mode=\"append\", properties=MYSQL_PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d8144-9234-4f07-8872-1af7e64d46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#orders_df.write.jdbc(url=MYSQL_URL, table=\"Orders\", mode=\"append\", properties=MYSQL_PROPERTIES)\n",
    "\n",
    "orders_df = spark.read.jdbc(url=ORDER_MYSQL_URL, table=\"Orders\", properties=MYSQL_PROPERTIES)\n",
    "products_df = spark.read.jdbc(url=PRODUCT_MYSQL_URL, table=\"Products\", properties=MYSQL_PROPERTIES)\n",
    "valid_order_ids = [row[\"order_id\"] for row in orders_df.select(\"order_id\").collect()]\n",
    "valid_product_ids = [row[\"product_id\"] for row in products_df.select(\"product_id\").collect()]\n",
    "valid_customer_ids = [row[\"customer_id\"] for row in customers_df.select(\"customer_id\").collect()]\n",
    "# ✅ Generate Order Items using only valid order_id & product_id\n",
    "def generate_order_items(n):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.choice(valid_order_ids), random.choice(valid_product_ids), \n",
    "          random.randint(1, 5), round(random.uniform(5, 500), 2)) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"order_item_id\", \"order_id\", \"product_id\", \"quantity\", \"unit_price\"]\n",
    "    )\n",
    "order_items_df = generate_order_items(100000)\n",
    "order_items_df.write.jdbc(url=ORDER_MYSQL_URL, table=\"Order_Items\", mode=\"append\", properties=MYSQL_PROPERTIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed681e4f-a7db-4b96-aed9-0d950de2e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Payments\n",
    "def generate_payments(n):\n",
    "    return spark.createDataFrame(\n",
    "        [(i,random.choice(valid_order_ids), fake.date_this_decade(), \n",
    "          random.choice([\"Credit Card\", \"PayPal\", \"Gift Card\", \"Bank Transfer\"]), \n",
    "          round(random.uniform(10, 500), 2), random.choice([\"Success\", \"Failed\", \"Pending\"])) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"payment_id\", \"order_id\", \"payment_date\", \"payment_method\", \"amount\", \"status\"]\n",
    "    )\n",
    "payments_df = generate_payments(10000)\n",
    "valid_payments_ids = [row[\"payment_id\"] for row in payments_df.select(\"payment_id\").collect()]\n",
    "\n",
    "# Generate Purchase History\n",
    "def generate_purchase_history(n):\n",
    "    return spark.createDataFrame(\n",
    "        [(i,random.choice(valid_customer_ids), random.choice(valid_order_ids), \n",
    "          fake.date_this_decade(), round(random.uniform(10, 500), 2)) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"history_id\", \"customer_id\", \"order_id\", \"purchase_date\", \"amount_spent\"]\n",
    "    )\n",
    "\n",
    "payments_df.write.jdbc(url=ORDER_MYSQL_URL, table=\"Payments\", mode=\"append\", properties=MYSQL_PROPERTIES)\n",
    "purchase_history_df = generate_purchase_history(1000)\n",
    "purchase_history_df.distinct().write.jdbc(url=ORDER_MYSQL_URL, table=\"Purchase_History\", mode=\"append\", properties=MYSQL_PROPERTIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8499c8-bf7a-4b00-bbf6-a38667e40133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate Usage History\n",
    "def generate_usage_history(n):\n",
    "    return spark.createDataFrame(\n",
    "        [(i,random.choice(valid_customer_ids),random.choice(valid_product_ids),fake.date_this_decade(), fake.sentence(nb_words=10), \n",
    "          random.choice([\"Returned\", \"Not Returned\"])) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"usage_id\", \"customer_id\", \"product_id\", \"usage_date\", \"feedback\", \"return_status\"]\n",
    "    )\n",
    "\n",
    "# Generate Transactions\n",
    "def generate_transactions(n,):\n",
    "    return spark.createDataFrame(\n",
    "        [(i, random.choice(valid_customer_ids), random.choice(valid_order_ids), \n",
    "          random.choice(valid_payments_ids), fake.date_this_decade(), \n",
    "          round(random.uniform(10, 500), 2), random.choice([\"Purchase\", \"Refund\"]), \n",
    "          random.choice([\"Completed\", \"Failed\", \"Pending\"])) \n",
    "         for i in range(1, n+1)], \n",
    "        [\"transaction_id\", \"customer_id\", \"order_id\", \"payment_id\", \"transaction_date\", \n",
    "         \"amount\", \"transaction_type\", \"status\"]\n",
    "    )\n",
    "usage_history_df = generate_usage_history(1000)\n",
    "usage_history_df.distinct().write.jdbc(url=ORDER_MYSQL_URL, table=\"Usage_History\", mode=\"append\", properties=MYSQL_PROPERTIES)\n",
    "\n",
    "transactions_df = generate_transactions(1000)\n",
    "transactions_df.distinct().write.jdbc(url=ORDER_MYSQL_URL, table=\"Transactions\", mode=\"append\", properties=MYSQL_PROPERTIES)\n",
    "\n",
    "print(\"✅ Data successfully written to MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069b0ab-89a1-4102-9c60-4c639a9b8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,rand,lit\n",
    "# Generate random login data\n",
    "def generate_logins(customers_df, num_attempts=50):\n",
    "    logins = []\n",
    "    for row in customers_df.collect():\n",
    "        customer_id = row[\"customer_id\"]\n",
    "        num_logins = random.randint(1, num_attempts)  # Random login attempts per customer\n",
    "        \n",
    "        for _ in range(num_logins):\n",
    "            ip = f\"192.168.{random.randint(0, 255)}.{random.randint(0, 255)}\"\n",
    "            login_attempt = random.choice([\"SUCCESS\", \"FAILURE\"])\n",
    "            login_date = f\"2024-02-{random.randint(1, 28)}\"\n",
    "            \n",
    "            logins.append((customer_id, ip, login_attempt, login_date))\n",
    "    \n",
    "    return logins\n",
    "\n",
    "# Generate synthetic login data\n",
    "login_data = generate_logins(customers_df)\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"customer_id\", \"ip_address\", \"login_attempt\", \"login_date\"]\n",
    "login_df = spark.createDataFrame(login_data, columns)\n",
    "\n",
    "# Introduce suspicious activity (customers with >3 IPs or >10 attempts)\n",
    "login_df = login_df.withColumn(\"is_suspicious\", when((rand() < 0.2), lit(1)).otherwise(lit(0)))\n",
    "\n",
    "# Write to MySQL (optional)\n",
    "login_df.write.jdbc(url=USER_MYSQL_URL, table=\"LoginHistory\", mode=\"append\", properties=MYSQL_PROPERTIES)\n",
    "\n",
    "# Show result\n",
    "login_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2696a-9227-43f4-939b-b782bf27dedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
